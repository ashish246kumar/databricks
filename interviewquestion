Spark Core is the general execution engine for the Spark platform, responsible for tasks such 
as scheduling, distributing, and monitoring applications.

__________________
List Comprehension

A list comprehension is a concise way to create lists in Python —
it allows you to write a single line of code instead of a multi-line for loop.
squares = [i * i for i in range(5)]
__________

A lambda function is a small, anonymous function defined without a name —
typically used for short, simple operations that you don’t want to formally define using def.
lambda arguments: expression
square = lambda x: x * x
print(square(5))

___________________________________________________________
Described the hybrid approach of maintaining a current data table and a historical changes table.

In data warehousing, a hybrid approach combines the benefits of real-time updates and full historical tracking.
We maintain two tables — one for current data and one for historical changes.

When an update happens, the old record is moved to the history table with effective start and end dates, and the current table is updated with the new value.
In Current Table, we update:

Customer_ID | Name   | Address | IsActive
-----------------------------------------
101          | Rajesh | Mumbai  | Y


✅ In History Table, we insert the old record:

Customer_ID | Old_Address | Effective_Start | Effective_End | IsActive
---------------------------------------------------------------------
101          | Delhi       | 2024-01-01      | 2025-01-15     | N


____________________________________________________________________
scd
__________

Slowly Changing Dimensions, or SCDs, are techniques used in data warehousing to track and manage 
changes in dimension table attributes over time — such as a customer’s address or an employee’s department

| **Type**                    | **Description**                                                                                             | **Example**                                                                                                              |
| --------------------------- | ----------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------ |
| **Type 0 – Passive**        | No changes are tracked; once stored, values remain fixed.                                                   | Student’s admission major remains the same even if changed later.                                                        |
| **Type 1 – Overwrite**      | Old data is replaced by new data; no history maintained.                                                    | Customer’s old address replaced by new one.                                                                              |
| **Type 2 – New Record**     | A new record is created when data changes; full history preserved with effective dates or flags.            | Product’s price change creates a new record with new `start_date` and `end_date`.                                        |
| **Type 3 – New Column**     | Adds a new column to store the previous value; only one level of history retained.                          | Employee’s previous role stored in “Previous_Role” column.                                                               |
| **Type 4 – History Table**  | Separate history table maintains old records; main table holds current data.                                | Old store details pushed to “Store_History” table when location changes.                                                 |
| **Type 6 – Hybrid (1+2+3)** | Combination of Types 1, 2, and 3 — overwriting, adding new records, and tracking previous columns together. | Salesperson changes region → new record (Type 2), previous region column updated (Type 3), contact overwritten (Type 1). |

________________________________________________________________________________
FACT vs DIM

A fact table is the central table in a data warehouse that stores measurable data — things you can count or sum, such as sales amount, units sold, or revenue.
It answers what happened in the business, while dimension tables explain who, what, when, and where.
For example, in a retail business, the fact table might have columns like Product_ID, Store_ID, Date_ID, and measures such as Units_Sold and Revenue. 
These foreign keys link to dimensions for deeper analysis.

There are three main types:
Transactional — records every individual event, like each sale.
Snapshot — captures the state at regular intervals, like daily inventory.
Accumulating — tracks progress of a process, like order to delivery.
Accumulating fact table — tracks processes with defined start and end points, such as an order from booking to delivery


A dimension table contains descriptive attributes about business entities — like products, customers, stores, or dates.
It provides context to the numbers in a fact table, answering the who, what, where, when of a business event.
It gives context to the numbers in a fact table
For example, instead of seeing just Product_ID = 101, the dimension table tells you that it’s “iPhone 15”, belongs to the “Smartphones” category, and is made by “Apple”.


| **Feature**           | **Fact Table**                                                          | **Dimension Table**                                                          |
| --------------------- | ----------------------------------------------------------------------- | ---------------------------------------------------------------------------- |
| **Purpose**           | Stores measurable, quantitative business data (facts or metrics).       | Stores descriptive, contextual information about business entities.          |
| **Type of Data**      | Numeric data (e.g., sales amount, quantity, profit).                    | Text or descriptive data (e.g., product name, customer name, location).      |
| **Foreign Key**       | Contains foreign keys referencing dimension tables.                     | Does **not** contain foreign keys from fact tables (only primary key).       |
| **Operations**        | Used for aggregations like SUM, AVG, COUNT during analysis.             | Used for filtering, grouping, and labeling facts in reports.                 |
| **Size**              | Usually very large (millions or billions of records).                   | Smaller in size compared to fact tables.                                     |
| **Refresh Frequency** | Updated frequently (as new transactions occur).                         | Changes rarely — mostly when entity attributes change.                       |
| **Example**           | Sales_Fact (Date_ID, Product_ID, Customer_ID, Units_Sold, Revenue).     | Product_Dim (Product_ID, Product_Name, Category, Brand, Price).              |

______________________________________________________________________________________________________
An index is a database structure (like a lookup table) that helps the database find rows faster without scanning the entire table.
Think of it like an index in a book — it points you to the page where information is located instead of reading every page.
Without an index → Database performs a full table scan (checks every row).
With an index → Database uses the index to quickly locate rows matching the condition.

Internally, traditional databases implement indexes using data structures like B-trees or hash tables.
A B-tree index maintains sorted keys and pointers to rows, allowing logarithmic time lookups.
Each insert or update operation must also maintain this index structure, which is why indexes speed up reads but can slow down writes
When you insert, update, or delete rows:
The DB must also update the index structure.
This is why write-heavy tables can get slower with too many indexes.
The indexed key is passed through a hash function.
The function returns a hash value that points directly to the data location.
Lookup time is O(1) on average (very fast for equality searches
____________________________________________________________


| Question                                                | Answer  | Explanation                                                     |
| ------------------------------------------------------- | ------- | --------------------------------------------------------------- |
| 1️⃣ Indexes improve the speed of data retrieval.        | ✅ True  | Indexes make searches faster by avoiding full table scans.      |
| 2️⃣ Indexes slow down data insertion and updates.       | ✅ True  | Because the index must be updated whenever data changes.        |
| 3️⃣ You can create an index on multiple columns.        | ✅ True  | That’s called a **composite index**.                            |
| 4️⃣ Indexes reduce storage space.                       | ❌ False | They actually **consume extra space** in the database.          |
| 5️⃣ Indexes are automatically created on every column.  | ❌ False | You must explicitly create them (except for primary keys).      |
| 6️⃣ A primary key automatically creates a unique index. | ✅ True  | Most databases do this under the hood.                          |
| 7️⃣ Too many indexes always improve performance.        | ❌ False | Too many indexes can **slow down writes** and use extra memory. |

Internally, traditional databases implement indexes using data structures like B-trees or hash tables.
A B-tree index maintains sorted keys and pointers to rows, allowing logarithmic time lookups.
Each insert or update operation must also maintain this index structure, which is why indexes speed up reads but can slow down writes
______________________________________________________________________________

WINDOW Functions:  Provided use cases for RANK(), DENSE_RANK() for ordering data within partitions

Window functions are used to perform calculations across a set of rows that are related to the current row —
without collapsing them into a single result like aggregation does

RANK() gives the same rank to ties, but skips the next number (notice both 400’s get rank 1, and the next rank would be 3).
DENSE_RANK() does not skip ranks after a tie.
So if two rows share rank 1, the next is 2 (not 3).





_______________________________________________________________________________________

SELF JOIN Applications:  Discussed scenarios like finding manager-employee relationships within the same table

A SELF JOIN is when a table is joined to itself —
you treat the same table as two different tables using aliases.
This is useful when rows within the same table are related to each other — for example:

SELECT 
    e.emp_name AS employee,
    m.emp_name AS manager
FROM employees e
LEFT JOIN employees m
ON e.manager_id = m.emp_id;


________________________________________

HAVING vs WHERE:  Explained how WHERE filters rows before aggregation, whereas HAVING filters groups post-aggregation
explain this 

WHERE is used to filter individual rows before any grouping or aggregation happens.
HAVING is used to filter aggregated results after GROUP BY has been applied.


_____________________________________________________________________________________________________________________________________
Both Delta Lake and Parquet are file formats used in data lakes, but they serve different purposes.
Parquet is a storage format, while Delta is a storage layer built on top of Parquet that adds reliability, transaction support, and versioning

Parquet – Data Storage Format
Parquet is a columnar storage format.
It’s highly efficient for read-heavy analytics workloads.
It supports compression and encoding schemes for better performance.
However, it is immutable — once written, you can’t easily update or delete records.
It lacks ACID transactions and data versioning.
✅ Example use case: Great for storing large, append-only datasets for analytics (like logs or historical data).


| Feature            | Parquet              | Delta Lake                           |
| ------------------ | -------------------- | ------------------------------------ |
| Storage Type       | Columnar file format | Storage layer built on Parquet       |
| ACID Transactions  | ❌ No                 | ✅ Yes                                |
| Schema Enforcement | ❌ No                 | ✅ Yes                                |
| Updates/Deletes    | ❌ Hard               | ✅ Supported                          |
| Time Travel        | ❌ No                 | ✅ Yes                                |
| Streaming Support  | ❌ No                 | ✅ Yes                                |
| Metadata Handling  | Hive Metastore       | Delta transaction log (`_delta_log`) |
| Use Case           | Raw data storage     | Reliable data lake / Lakehouse       |

______________________________________________________________________________________________________

Delta Lake is an open-source storage layer that sits on top of Parquet files.
It adds features that Parquet alone doesn’t provide, such as:
ACID transactions (ensures reliability during concurrent writes)
Schema evolution and enforcement
Time travel (query old versions of data)
Merge, update, delete support
Streaming + batch unification
______________________________________________________________________________________________________


