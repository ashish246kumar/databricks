
________________________________________________________________________________________________________________________________
Delta Tables - Deletion Vectors and Liquid Clustering
_______________________
Deletion Vectors are an optimization feature in Delta Lake designed to improve the performance and efficiency of DELETE and UPDATE operations, especially on tables with millions of records [00:49].
How Deletion Vectors Work
Without Deletion Vectors (Standard Delta Table Behavior): If you delete a single row in a Parquet data file, the entire Parquet file must be rewritten to remove that row. This is inefficient and costly for small operations on large files [00:55].
With Deletion Vectors Enabled: Instead of rewriting the data file, a flag (the deletion vector) is added to the Delta Lake metadata, marking the specific row in the Parquet file as deleted [01:18].
When you query the data, Delta Lake uses the vector to filter out the flagged rows, only reading the non-deleted data [01:34].
The physical removal of the deleted rows only occurs later when a maintenance operation like OPTIMIZE or predictive optimize is run [01:44]. This allows for many small deletions to be batched and processed in one efficient rewrite.

Practical Demonstration
The video demonstrates the difference in operation history:
Deletion Vector Disabled: A DELETE command shows files being removed and new files being added (a file rewrite) to complete the operation [05:57].
Deletion Vector Enabled: A DELETE command shows 0 files removed and 0 files added. Instead, the operation matrix shows numDeletionVectorsAdded greater than zero, indicating the flags were added without a file rewrite [07:30].
2. Liquid Clustering
Liquid Clustering is an alternative to traditional static partitioning and Z-ordering techniques, providing a more flexible and dynamic way to optimize data layout for query performance [08:14].
Benefits and Scenarios
Liquid Clustering helps improve query performance, especially in scenarios where:
The data is queried using different access patterns over time [08:54].
You have columns with high cardinality on which you need to filter data [08:43].
The table has significant data skew [08:46].
The data is growing quickly [08:50].

Key Advantage
The main benefit is flexibility. Unlike partitioning or Z-ordering, you do not need to rewrite the data whenever
you decide to change or apply the clustering logic [08:20].
Automatic Maintenance: Once a cluster column is defined, any incremental data (new data being loaded) will automatically be clustered and organized by that column [08:35].
Dynamic Repartitioning: Delta Lake automatically takes care of properly repartitioning the file sizes for the selected cluster columns, so you don't have to manually manage partition schemes [08:58].
Implementation
Defining Cluster Columns: You define the clustering column(s) using the CLUSTER BY clause [09:31].
For an existing table, use the ALTER TABLE command: ALTER TABLE table_name CLUSTER BY (column_name) [09:41].
For a new table, use the CLUSTER BY clause during the CREATE TABLE command [10:48].
Limitations: Clustering columns must be within the first 32 columns of the Delta table [11:32].
Query Performance: Queries that use the clustering column in the WHERE predicate (filter) will benefit from the improved data organization [11:46].
Removing Clustering: You can remove the clustering by running ALTER TABLE table_name CLUSTER BY NONE [10:24].



Purpose,Query,Timestamp
Enable DV,ALTER TABLE dev.bronze.sales SET TBLPROPERTIES ( 'delta.enableDeletionVectors' = true ),
Delete Data (With DV),DELETE FROM dev.bronze.sales WHERE InvoiceNo = '5555',
View History,DESCRIBE HISTORY dev.bronze.sales,
Force File Compaction,OPTIMIZE dev.bronze.sales,



Purpose,Query,Timestamp
Set Clustering on Existing Table,ALTER TABLE dev.bronze.sales CLUSTER BY (InvoiceNo),
Remove Clustering,ALTER TABLE table_name CLUSTER BY NONE,
Create New Clustered Table,CREATE TABLE dev.bronze.sales_clustered CLUSTER BY (InvoiceNo) AS SELECT * FROM READ_FILES( ... ),
View Clustering Columns,DESCRIBE EXTENDED dev.bronze.sales_clustered,
Query Clustered Data,SELECT * FROM dev.bronze.sales_clustered WHERE InvoiceNo = '5555',

_________________________________________________________________________________________________________
Spark Memory Management | Why OOM Errors in Spark
___________________________

### 1. **Introduction to Spark Memory Management**  
   - Spark uses memory for two main purposes: **execution** (for tasks like shuffles, joins, and aggregations) and **storage** (for caching and persisting data).  
   - Memory management is crucial to avoid Out-of-Memory (OOM) errors, especially when dealing with large datasets in distributed environments.

**Key Interview Tip**: Start by explaining why memory management is important in distributed systems like Spark.

---

### 2. **JVM Memory Model in Spark**  
   - Spark runs on the JVM and uses two types of memory:  
     1. **On-Heap Memory**: Managed by the JVM, subject to garbage collection.  
     2. **Off-Heap Memory**: Managed outside the JVM to reduce garbage collection overhead.  

   - **Reserved Memory**: Spark reserves a small portion of the JVM heap (e.g., 300 MB by default) for its internal processes. This is not available for user tasks.

**Example to use**: If the JVM has 10GB allocated, about 300MB is reserved, leaving 9.7GB for Spark operations.

---

### 3. **Memory Division in Spark**  
   Spark divides the usable memory into two main parts:  
   1. **Execution Memory**: Used for intermediate computations like sort, shuffle, and aggregation.  
   2. **Storage Memory**: Used for caching RDDs/DataFrames and storing broadcast variables.  

   - Spark introduced a **Unified Memory Model** (from Spark 1.6+) to dynamically share memory between execution and storage tasks.  
     - For example, if storage memory isn’t fully used, execution memory can borrow it, and vice versa.  

**Key Interview Tip**: Mention how the unified model improves flexibility compared to the pre-1.6 versions where memory was statically divided.

---

### 4. **Memory Configuration in Spark**  
   - Spark memory is configured through the following parameters:
     1. **spark.executor.memory**: Total memory allocated to each executor.  
     2. **spark.memory.fraction**: Fraction of executor memory available for storage and execution (default: 60%).  
     3. **spark.memory.storageFraction**: Fraction of memory reserved for storage tasks (default: 50% of memory.fraction).  

   **Formula**:  
   Usable Memory = `spark.executor.memory * spark.memory.fraction`.  

**Example**:  
If `spark.executor.memory = 10GB` and `spark.memory.fraction = 0.6`, then usable memory = 6GB. Out of this, 3GB is reserved for storage, and 3GB for execution.

---

### 5. **Reasons for OOM Errors in Spark**  
   - **Garbage Collection (GC) Overhead**: Excessive on-heap memory usage can trigger frequent GC, causing delays or OOM errors.  
   - **Insufficient Memory for Execution**: Large shuffles, joins, or aggregations may exceed allocated execution memory.  
   - **Storage Spillage**: If there’s insufficient space for cached data, Spark spills data to disk, leading to performance issues.  

---

### 6. **Key Techniques to Avoid OOM Errors**  
   1. **Optimize Memory Configuration**: Increase `spark.executor.memory` or adjust `spark.memory.fraction`.  
   2. **Use Off-Heap Memory**: Enable `spark.memory.offHeap.enabled` for better GC performance.  
   3. **Avoid Skewed Data**: Partition data evenly to prevent memory overload on specific executors.  
   4. **Persist Data Efficiently**: Use proper storage levels (`DISK_ONLY`, `MEMORY_AND_DISK`) based on your use case.  
   5. **Broadcast Joins**: Use broadcast variables for small datasets to reduce shuffle memory usage.

---

### 7. **Falling Back to Disk (Spillage)**  
   - When Spark runs out of memory for execution or storage, it spills data to disk.  
   - This is a safety mechanism but can significantly degrade performance due to disk I/O overhead.  
   - Example: During a large join operation, intermediate shuffle data may spill to disk if execution memory is insufficient.

---

### 8. **Unified Memory Model in Detail**  
   - Prior to Spark 1.6, execution and storage memory were statically divided, leading to inefficiencies.  
   - The unified memory model dynamically shares memory between execution and storage, reducing wastage.  
   - Example: If cached RDDs use less storage memory, the unused portion is borrowed for execution tasks.

---

### 9. **Garbage Collection and Its Role**  
   - Spark relies on JVM garbage collection for on-heap memory management.  
   - Frequent GC can pause tasks and lead to OOM errors if memory isn’t managed efficiently.  
   - **Solution**: Use off-heap memory or tune JVM GC settings (e.g., G1GC).

---

### 10. **Conclusion**  
   - Summarize by stating that Spark’s memory management is a balance between execution, storage, and spillover mechanisms.  
   - Highlight how understanding and configuring memory parameters can prevent OOM errors and optimize performance.

---

**Key Interview Tip**:  
When explaining, always back your points with examples or practical scenarios (e.g., large shuffle operations causing spillage). 
If asked how to debug memory issues, mention tools like the Spark UI to monitor memory usage and task performance.
_________________________________________________________________________________________________________________________

Execution memory handles active tasks, ensuring computations proceed without delay. Storage memory is secondary and waits for execution's completion.
Why do you think computation needs priority?

Storage memory can't expand beyond what's free after execution memory's use. This avoids interruptions in processing.
Does that allocation make sense?
Execution memory dynamically adjusts, while storage memory is immune to eviction when full.

________________________________________________________________________________________

Immunity to Eviction: The Storage memory's own portion (default 50% of the Unified Memory) is immune to eviction by Execution tasks [10:25]. This is configured by spark.memory.storageFraction (default value is 0.5) [10:44].

Storage Must Wait: Storage tasks cannot evict Execution memory. If Storage needs more memory and Execution is currently using it, Storage has to wait until Execution completes and frees up the space [11:35].

Data Spilling (Storage) and Costly Operations
The video details what happens when data does not fit in the Storage memory and the performance impact of managing data off-memory.

Spilling to Disk: If a new partition is too large and the Storage memory is full (even after consuming all available Execution memory), the data will spill to disk [13:42].

Caching Strategy: This spilling only happens if the caching mechanism is set to MEMORY_AND_DISK [13:50]. If set to MEMORY_ONLY, it will result in an Out of Memory error if memory cannot be recycled [14:03].

Serialization/Deserialization Cost: Data is stored in memory in a deserialized format (Java objects) [14:34]. When it is spilled to disk, it must be serialized (converted into byte streams), and when read back, it must be deserialized [14:47]. This serialization and deserialization is a costly operation as it consumes both resources and time [15:03].

Execution Memory Split and Out of Memory (OOM) Errors
The video explains how Execution memory is divided and outlines common scenarios that cause Spark jobs to crash with OOM errors.

Execution Memory Split
The total Execution memory is split equally among the number of cores (or concurrent tasks) running on the executor [16:09]. For example, 40 MB of Execution memory with 4 cores means 10 MB is allocated per core/task [16:17].

Causes of Out of Memory (OOM) Errors
Single Record Larger than Task Memory: If a single record within a partition is larger than the total memory allocated to the task, Spark cannot split the record to spill it to disk and will immediately fail with an Out of Memory error [19:50].

Excessive Shuffle Data: Wide operations (like joins or aggregations) that require a shuffle and generate a large amount of shuffle data that is greater than the available memory can lead to OOM errors [20:29].

Large Broadcast Variables: If the size of a broadcast variable is greater than the available memory on the executor, it will result in an OOM error [20:47].

Data Explosion: Operations like cross joins or the explode function can lead to an explosion in data volume by multiplying the number of records [21:09]. If the resulting multiplied data size exceeds the memory, it will cause OOM errors [21:29].
_______________________________________________________
